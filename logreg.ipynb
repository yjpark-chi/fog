{"cells": [{"cell_type": "code", "execution_count": 1, "id": "89567b2b-68f4-4ebd-aa5e-7d1401371546", "metadata": {}, "outputs": [], "source": "import os \n#from fog.code.utils.utils import *\n\nimport pyspark.sql.functions as F\nfrom pyspark.sql.types import StringType, DoubleType\nfrom pyspark.sql import SparkSession\nfrom google.cloud import storage\n\n# import Spark stuff\nfrom pyspark import SparkFiles\nfrom pyspark.ml import Pipeline\nfrom pyspark.sql import SparkSession\nfrom pyspark.ml.feature import StringIndexer, IndexToString, VectorAssembler\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.mllib.evaluation import MulticlassMetrics\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator"}, {"cell_type": "code", "execution_count": 2, "id": "cd9beaa1-9aac-4238-8f49-db14b8717484", "metadata": {}, "outputs": [], "source": "spark = SparkSession.builder.appName('defog-labeled').getOrCreate()"}, {"cell_type": "code", "execution_count": 3, "id": "2d5f20b6-f31e-4bb0-b5c5-49f4a3a8d28e", "metadata": {}, "outputs": [], "source": "defog_path = \"parkinsons_data/train/processed/defog_tasks_lagging\"\ntop_bucket_name = \"msca-bdp-student-gcs\""}, {"cell_type": "code", "execution_count": 4, "id": "632ce81d-4238-4a66-bbcd-d91c48f4b1cc", "metadata": {}, "outputs": [], "source": "def feed_files(top_bucket_name, prefix, suffix):\n    client = storage.Client()\n    blobs = client.list_blobs(top_bucket_name, prefix=prefix)\n\n    processed = None\n\n    for i, blob in enumerate(blobs):\n        print(blob.name)\n        if blob.name.endswith(suffix):\n            \n            if suffix == \".parquet\":\n                df = spark.read.parquet(f\"gs://{top_bucket_name}/{blob.name}\")\n            elif suffix == \".csv\":\n                df = spark.read.csv(f\"gs://{top_bucket_name}/{blob.name}\")\n            if processed is None:\n                processed = df\n            else:\n                processed = processed.union(df)\n    return processed\n\n"}, {"cell_type": "code", "execution_count": 5, "id": "1132ec70-5ead-42e4-a98a-02d686c9193c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "parkinsons_data/train/processed/defog_tasks_lagging/\nparkinsons_data/train/processed/defog_tasks_lagging/_SUCCESS\nparkinsons_data/train/processed/defog_tasks_lagging/part-00000-eae2acef-cda6-49a5-b43f-ded309b7bad5-c000.snappy.parquet\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "parkinsons_data/train/processed/defog_tasks_lagging/part-00001-eae2acef-cda6-49a5-b43f-ded309b7bad5-c000.snappy.parquet\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "parkinsons_data/train/processed/defog_tasks_lagging/part-00002-eae2acef-cda6-49a5-b43f-ded309b7bad5-c000.snappy.parquet\nparkinsons_data/train/processed/defog_tasks_lagging/part-00003-eae2acef-cda6-49a5-b43f-ded309b7bad5-c000.snappy.parquet\nparkinsons_data/train/processed/defog_tasks_lagging/part-00004-eae2acef-cda6-49a5-b43f-ded309b7bad5-c000.snappy.parquet\nparkinsons_data/train/processed/defog_tasks_lagging/part-00005-eae2acef-cda6-49a5-b43f-ded309b7bad5-c000.snappy.parquet\nparkinsons_data/train/processed/defog_tasks_lagging/part-00006-eae2acef-cda6-49a5-b43f-ded309b7bad5-c000.snappy.parquet\nparkinsons_data/train/processed/defog_tasks_lagging/part-00007-eae2acef-cda6-49a5-b43f-ded309b7bad5-c000.snappy.parquet\nparkinsons_data/train/processed/defog_tasks_lagging/part-00008-eae2acef-cda6-49a5-b43f-ded309b7bad5-c000.snappy.parquet\nparkinsons_data/train/processed/defog_tasks_lagging/part-00009-eae2acef-cda6-49a5-b43f-ded309b7bad5-c000.snappy.parquet\nparkinsons_data/train/processed/defog_tasks_lagging/part-00010-eae2acef-cda6-49a5-b43f-ded309b7bad5-c000.snappy.parquet\nparkinsons_data/train/processed/defog_tasks_lagging/part-00011-eae2acef-cda6-49a5-b43f-ded309b7bad5-c000.snappy.parquet\nparkinsons_data/train/processed/defog_tasks_lagging/part-00012-eae2acef-cda6-49a5-b43f-ded309b7bad5-c000.snappy.parquet\nparkinsons_data/train/processed/defog_tasks_lagging/part-00013-eae2acef-cda6-49a5-b43f-ded309b7bad5-c000.snappy.parquet\nparkinsons_data/train/processed/defog_tasks_lagging/part-00014-eae2acef-cda6-49a5-b43f-ded309b7bad5-c000.snappy.parquet\nparkinsons_data/train/processed/defog_tasks_lagging/part-00015-eae2acef-cda6-49a5-b43f-ded309b7bad5-c000.snappy.parquet\nparkinsons_data/train/processed/defog_tasks_lagging/part-00016-eae2acef-cda6-49a5-b43f-ded309b7bad5-c000.snappy.parquet\nparkinsons_data/train/processed/defog_tasks_lagging/part-00017-eae2acef-cda6-49a5-b43f-ded309b7bad5-c000.snappy.parquet\nparkinsons_data/train/processed/defog_tasks_lagging/part-00018-eae2acef-cda6-49a5-b43f-ded309b7bad5-c000.snappy.parquet\nparkinsons_data/train/processed/defog_tasks_lagging/part-00019-eae2acef-cda6-49a5-b43f-ded309b7bad5-c000.snappy.parquet\nparkinsons_data/train/processed/defog_tasks_lagging/part-00020-eae2acef-cda6-49a5-b43f-ded309b7bad5-c000.snappy.parquet\nparkinsons_data/train/processed/defog_tasks_lagging/part-00021-eae2acef-cda6-49a5-b43f-ded309b7bad5-c000.snappy.parquet\nparkinsons_data/train/processed/defog_tasks_lagging/part-00022-eae2acef-cda6-49a5-b43f-ded309b7bad5-c000.snappy.parquet\nparkinsons_data/train/processed/defog_tasks_lagging/part-00023-eae2acef-cda6-49a5-b43f-ded309b7bad5-c000.snappy.parquet\nparkinsons_data/train/processed/defog_tasks_lagging/part-00024-eae2acef-cda6-49a5-b43f-ded309b7bad5-c000.snappy.parquet\nparkinsons_data/train/processed/defog_tasks_lagging/part-00025-eae2acef-cda6-49a5-b43f-ded309b7bad5-c000.snappy.parquet\nparkinsons_data/train/processed/defog_tasks_lagging/part-00026-eae2acef-cda6-49a5-b43f-ded309b7bad5-c000.snappy.parquet\nparkinsons_data/train/processed/defog_tasks_lagging/part-00027-eae2acef-cda6-49a5-b43f-ded309b7bad5-c000.snappy.parquet\nparkinsons_data/train/processed/defog_tasks_lagging/part-00028-eae2acef-cda6-49a5-b43f-ded309b7bad5-c000.snappy.parquet\n"}], "source": "defog = feed_files(top_bucket_name, defog_path, \".parquet\")"}, {"cell_type": "code", "execution_count": 6, "id": "287a778e-9b69-4b06-b075-f49a04cfe0a2", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- Subject: string (nullable = true)\n |-- Id: string (nullable = true)\n |-- Time: float (nullable = true)\n |-- AccV: float (nullable = true)\n |-- AccML: float (nullable = true)\n |-- AccAP: float (nullable = true)\n |-- StartHesitation: integer (nullable = true)\n |-- Turn: integer (nullable = true)\n |-- Walking: integer (nullable = true)\n |-- Valid: boolean (nullable = true)\n |-- Task: boolean (nullable = true)\n |-- SourceDefog: integer (nullable = true)\n |-- Age: integer (nullable = true)\n |-- Sex: string (nullable = true)\n |-- YearsSinceDx: integer (nullable = true)\n |-- UPDRSIII_On: integer (nullable = true)\n |-- UPDRSIII_Off: integer (nullable = true)\n |-- NFOGQ: integer (nullable = true)\n |-- TimeSeconds: double (nullable = true)\n |-- Begin: double (nullable = true)\n |-- End: double (nullable = true)\n |-- TaskType: string (nullable = true)\n |-- MB9: integer (nullable = true)\n |-- Rest1: integer (nullable = true)\n |-- MB6-L: integer (nullable = true)\n |-- MB6-R: integer (nullable = true)\n |-- Turning-C: integer (nullable = true)\n |-- MB2a: integer (nullable = true)\n |-- MB3-L: integer (nullable = true)\n |-- MB12: integer (nullable = true)\n |-- MB5: integer (nullable = true)\n |-- MB3-R: integer (nullable = true)\n |-- MB13: integer (nullable = true)\n |-- TUG-DT: integer (nullable = true)\n |-- Turning-ST: integer (nullable = true)\n |-- TUG-ST: integer (nullable = true)\n |-- 4MW-C: integer (nullable = true)\n |-- Hotspot2: integer (nullable = true)\n |-- MB6: integer (nullable = true)\n |-- TUG-C: integer (nullable = true)\n |-- 4MW: integer (nullable = true)\n |-- Hotspot1-C: integer (nullable = true)\n |-- Hotspot2-C: integer (nullable = true)\n |-- MB8: integer (nullable = true)\n |-- Hotspot1: integer (nullable = true)\n |-- MB4: integer (nullable = true)\n |-- MB1: integer (nullable = true)\n |-- MB7: integer (nullable = true)\n |-- Rest2: integer (nullable = true)\n |-- MB2b: integer (nullable = true)\n |-- MB10: integer (nullable = true)\n |-- Turning-DT: integer (nullable = true)\n |-- MB11: integer (nullable = true)\n |-- target: integer (nullable = true)\n |-- features: vector (nullable = true)\n |-- standardized: vector (nullable = true)\n |-- prediction_67: integer (nullable = true)\n |-- prediction4: integer (nullable = true)\n |-- AccV_lag1: float (nullable = true)\n |-- AccV_lag2: float (nullable = true)\n |-- AccV_lag3: float (nullable = true)\n |-- AccV_lag4: float (nullable = true)\n |-- AccV_lag5: float (nullable = true)\n |-- AccV_lag6: float (nullable = true)\n |-- AccV_lag7: float (nullable = true)\n |-- AccV_lag8: float (nullable = true)\n |-- AccV_lag9: float (nullable = true)\n |-- AccV_lag10: float (nullable = true)\n |-- AccML_lag1: float (nullable = true)\n |-- AccML_lag2: float (nullable = true)\n |-- AccML_lag3: float (nullable = true)\n |-- AccML_lag4: float (nullable = true)\n |-- AccML_lag5: float (nullable = true)\n |-- AccML_lag6: float (nullable = true)\n |-- AccML_lag7: float (nullable = true)\n |-- AccML_lag8: float (nullable = true)\n |-- AccML_lag9: float (nullable = true)\n |-- AccML_lag10: float (nullable = true)\n |-- AccAP_lag1: float (nullable = true)\n |-- AccAP_lag2: float (nullable = true)\n |-- AccAP_lag3: float (nullable = true)\n |-- AccAP_lag4: float (nullable = true)\n |-- AccAP_lag5: float (nullable = true)\n |-- AccAP_lag6: float (nullable = true)\n |-- AccAP_lag7: float (nullable = true)\n |-- AccAP_lag8: float (nullable = true)\n |-- AccAP_lag9: float (nullable = true)\n |-- AccAP_lag10: float (nullable = true)\n\n"}], "source": "# drop Test, Visit, Medication cols because they were for tdcsfog\ndefog = defog.drop(\"Test\", \"Visit\", \"Medication\")\n\n# keep only when valid = True\ndefog = defog.filter(F.col(\"Valid\")==True).filter(F.col(\"Task\")==True)\n\n# convert Time to float\ndefog = defog.withColumn(\"Time\", F.col(\"Time\").cast(\"float\"))\ndefog.printSchema()"}, {"cell_type": "code", "execution_count": 7, "id": "6445400f-ef05-4d4e-9bc9-877b34e769a8", "metadata": {}, "outputs": [], "source": "# create sex binary cols\ndefog = defog.withColumn('SexInd', \n                  F.when((F.col(\"Sex\") == \"F\"), 1) \\\n                    .when((F.col(\"Sex\") == \"M\"), 0)\n                  )"}, {"cell_type": "code", "execution_count": 8, "id": "e9c27dc8-5abd-460e-918a-2fec0c9d54d2", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# convert task types to multilabels\n# keep null tasks for now\nfrom pyspark.ml.feature import StringIndexer\n\nindexer = StringIndexer(inputCol='TaskType', outputCol='TaskTypeInd', handleInvalid=\"keep\")\nmodel = indexer.fit(defog)\ndefog = model.transform(defog)\n\n# use model.labels to see the order of the labels"}, {"cell_type": "code", "execution_count": 9, "id": "bc162102-262e-46e0-9767-2dd8fa3f4c2a", "metadata": {}, "outputs": [], "source": "# remove unnecessary cols\ndefog = defog.drop(\"Subject\", \"Sex\", \"Id\", \"TaskType\")"}, {"cell_type": "code", "execution_count": 10, "id": "80a6285f-2918-4856-b71d-bb6c77ae5a2f", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+------+-------+\n|target|  count|\n+------+-------+\n|     1|     88|\n|     3|  70521|\n|     2| 414380|\n|     0|3626334|\n+------+-------+\n\n"}], "source": "defog.groupBy(\"target\").count().show()"}, {"cell_type": "code", "execution_count": 11, "id": "3536b3fd-8402-4393-96d3-340af32da47e", "metadata": {}, "outputs": [], "source": "# feature selection\n# ignore standardized for now\ndef vectorize():\n    \"\"\"\n    Creates vectorized dataframe.\n    \"\"\"\n    \"\"\"\n    feature_cols = [\"AccV\", \"AccML\", \"AccAP\", \"TaskTypeInd\",\n        \"AccV_lag1\", \"AccV_lag2\", \"AccV_lag3\", \"AccV_lag4\", \"AccV_lag5\",\n        \"AccV_lag6\", \"AccV_lag7\", \"AccV_lag8\", \"AccV_lag9\", \"AccV_lag10\",\n        \"AccML_lag1\", \"AccML_lag2\", \"AccML_lag3\", \"AccML_lag4\", \"AccML_lag5\",\n        \"AccML_lag6\", \"AccML_lag7\", \"AccML_lag8\", \"AccML_lag9\", \"AccML_lag10\",\n        \"AccAP_lag1\", \"AccAP_lag2\", \"AccAP_lag3\", \"AccAP_lag4\", \"AccAP_lag5\",\n        \"AccAP_lag6\", \"AccAP_lag7\", \"AccAP_lag8\", \"AccAP_lag9\", \"AccAP_lag10\",\n        \"prediction4\"]\n    \"\"\"\n    #feature_cols = ['standardized'] + [\"TaskTypeInd\", \"prediction4\"]\n    label_cols = ['target', 'StartHesitation', 'Turn', 'Walking']\n    feature_cols = [\"AccV\", \"AccML\", \"AccAP\", \"TaskTypeInd\", \"prediction4\"]\n\n    defog_sel = defog.select(feature_cols + label_cols)\n    assembler = VectorAssembler(inputCols=feature_cols, outputCol='features', handleInvalid=\"skip\")\n    vectorized = assembler.transform(defog_sel)\n    return vectorized"}, {"cell_type": "code", "execution_count": 12, "id": "b44b8e7f-17f3-4699-8753-e96d4e87fb5b", "metadata": {}, "outputs": [], "source": "def run_logreg(train, test, labelCol):\n    \"\"\"\n    Run the logistic regression model.\n    \"\"\"\n    # create model\n    lgr = LogisticRegression(maxIter=10, featuresCol = 'features', labelCol=labelCol)\n\n    # fit model\n    lgrm = lgr.fit(train)\n\n    # make predictions\n    predictions = lgrm.transform(test)\n\n    return predictions\n\n\ndef get_f1(precision, recall):\n    \"\"\"\n    Calculate f1 score.\n    \"\"\"\n    if precision + recall == 0:\n        return 0\n    return 2 * ((precision * recall)/(precision + recall))\n\ndef get_accuracy(labels):\n    \"\"\"\n    Calculate the accuracy for each label by creating a confusion matrix.\n    \"\"\"\n    accs = {}\n\n    preds_labels = predictions.select(F.col(\"prediction\").cast(DoubleType()), F.col(\"target\").cast(DoubleType())).orderBy('prediction')\n\n    preds_labels = preds_labels.select(['prediction','target'])\n    metrics = MulticlassMetrics(preds_labels.rdd.map(tuple))\n    matrix = metrics.confusionMatrix().toArray()\n    for label in labels:\n        TN = 0\n        FN = 0\n        TP = 0\n        FP = 0\n        for i, row in enumerate(matrix):\n            for j, col in enumerate(row):\n                if i != label and j != label:\n                    TN += matrix[i, j]\n                elif i != label and j == label:\n                    FN += matrix[i, j]\n                elif i == label and j == label:\n                    TP += matrix[i, j]\n                elif i == label and j != label:\n                    FP += matrix[i, j]\n        print(f\"label: {label}, TP: {TP}, TN: {TN}, FP: {FP}, FN: {FN}\")\n        if (TP + TN + FP + FN) == 0:\n            acc = 0\n        else:\n            acc = (TP + TN)/(TP + TN + FP + FN)\n        accs[label] = acc\n    return accs\n\ndef evaluate(predictions, labels):\n    \"\"\"\n    Evaluate model performance by computing accuracy and f1 scores.\n    \"\"\"\n    evaluator = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\")\n    print(\"Overall\")\n    print(\"Accuracy\", evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"}))\n    weighted_precision = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n    weighted_recall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n    weighted_f1 = get_f1(weighted_precision, weighted_recall)\n    print(\"F1\", weighted_f1)\n    \n    accs = get_accuracy(labels)\n    f1_dict = {}\n    for label in labels:\n        print(label)\n        precision = evaluator.evaluate(predictions, {evaluator.metricLabel: label, evaluator.metricName: \"precisionByLabel\"})\n        recall = evaluator.evaluate(predictions, {evaluator.metricLabel: label, evaluator.metricName: \"recallByLabel\"})\n        f1 = get_f1(precision, recall) \n        print(\"Accuracy\", accs[label])\n        print(\"F1\", f1)\n        f1_dict[label] = f1\n\n    return evaluator, accs, f1_dict"}, {"cell_type": "markdown", "id": "2fa06aba-491a-4ada-8671-98ed8b78e984", "metadata": {}, "source": "Lag features, not standardized:  \n> Accuracy 0.8811464693942825  \nF1 0.8278086328796053\n\nNo lag, standardized:  \n>Accuracy 0.8818123580030658  \nF1 0.8396314248066408  \n\nNo lag, unstandardized:  \n>Accuracy 0.8819386763598863  \nF1 0.8404164161360337  \n\nUse unstandardized, no lag\n"}, {"cell_type": "code", "execution_count": 16, "id": "86accbc7-0e34-4e37-aca6-74f222f910cd", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/05/22 17:28:52 WARN com.github.fommil.netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n23/05/22 17:28:52 WARN com.github.fommil.netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n                                                                                \r"}], "source": "# no lag, unstandardized\nvectorized = vectorize()\ntrain, test = vectorized.randomSplit([0.8, 0.2],0.0)\npredictions = run_logreg(train, test, 'target')"}, {"cell_type": "code", "execution_count": 17, "id": "b6c0f257-6103-4f3f-b617-b93dc291c83a", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Overall\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Accuracy 0.8813211100183447\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "F1 0.8564489026360321\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "label: 0.0, TP: 718062.0, TN: 6900.0, FP: 6992.0, FN: 90627.0\nlabel: 1.0, TP: 0.0, TN: 822563.0, FP: 18.0, FN: 0.0\nlabel: 2.0, TP: 6896.0, TN: 732260.0, FP: 76429.0, FN: 6996.0\nlabel: 3.0, TP: 0.0, TN: 808397.0, FP: 14184.0, FN: 0.0\n0.0\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Accuracy 0.8813259727613451\nF1 0.9364448664002094\n1.0\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Accuracy 0.9999781176564982\nF1 0\n2.0\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Accuracy 0.8985814162982125\nF1 0.14153041472756475\n3.0\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 91:=====================================================>(278 + 1) / 279]\r"}, {"name": "stdout", "output_type": "stream", "text": "Accuracy 0.9827567133206335\nF1 0\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "evaluator = evaluate(predictions, [0.0, 1.0, 2.0, 3.0])"}, {"cell_type": "code", "execution_count": 18, "id": "c2c070bb-cc72-4402-8ae5-8d00d74076d2", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 93:=====================================================>(278 + 1) / 279]\r"}, {"name": "stdout", "output_type": "stream", "text": "+----------+------+\n|prediction| count|\n+----------+------+\n|       0.0|809718|\n|       2.0| 13813|\n+----------+------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "predictions.select('prediction').groupBy('prediction').count().show()"}, {"cell_type": "markdown", "id": "64264b21-6886-4854-8690-7368c6b143ed", "metadata": {}, "source": "Our algorithm can't predict labels 1 and 3.\nWe will try to treat it as a binary classification problem.  \n\nTry classifying label 1 = Start Hesitation"}, {"cell_type": "code", "execution_count": 19, "id": "a97ea15b-cb5d-41e6-a213-7597e5385254", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+---------------+-------+\n|StartHesitation|  count|\n+---------------+-------+\n|              1|     88|\n|              0|4111235|\n+---------------+-------+\n\n"}], "source": "vectorized.groupBy('StartHesitation').count().show()"}, {"cell_type": "code", "execution_count": 20, "id": "86971af7-a79d-4874-a589-644e492df844", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Overall\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Accuracy 0.8821894436581754\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "F1 0.8269711820180207\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "label: 0.0, TP: 724933.0, TN: 0.0, FP: 0.0, FN: 96810.0\nlabel: 1.0, TP: 0.0, TN: 821723.0, FP: 20.0, FN: 0.0\n0.0\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Accuracy 0.8821894436581754\nF1 0.9374077052983302\n1.0\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 151:====================================================>(369 + 1) / 370]\r"}, {"name": "stdout", "output_type": "stream", "text": "Accuracy 0.9999756614902713\nF1 0\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "(MulticlassClassificationEvaluator_8406fdb4c76f,\n {0.0: 0.8821894436581754, 1.0: 0.9999756614902713},\n {0.0: 0.9374077052983302, 1.0: 0})"}, "execution_count": 20, "metadata": {}, "output_type": "execute_result"}], "source": "# binary target=1\npredictions = run_logreg(train, test, 'StartHesitation')\nevaluate(predictions, [0.0, 1.0])"}, {"cell_type": "code", "execution_count": 21, "id": "a5021cdc-65fc-4d89-9a9b-268f8254c6e2", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 153:====================================================>(369 + 1) / 370]\r"}, {"name": "stdout", "output_type": "stream", "text": "+----------+------+\n|prediction| count|\n+----------+------+\n|       0.0|821743|\n+----------+------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# show predicted labels\npredictions.groupBy(\"prediction\").count().show()"}, {"cell_type": "markdown", "id": "0f17a47d-d395-4443-b3d4-0997d33c2065", "metadata": {}, "source": "Treating label 1 as a binary problem doesn't improve classification. We will try to undersample the data instead."}, {"cell_type": "code", "execution_count": 15, "id": "95ab9f72-1e1c-4ecd-9642-174eacda3c7a", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 43:=====================================================>(915 + 1) / 916]\r"}, {"name": "stdout", "output_type": "stream", "text": "+---------------+-----+\n|StartHesitation|count|\n+---------------+-----+\n|              1|   88|\n|              0|  526|\n+---------------+-----+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "def resample(large_dataframe, ratio, class_field, base_class):\n    \"\"\"\n    Resamples non-minority label by a chosen factor\n    \"\"\"\n    pos = large_dataframe.filter(large_dataframe[class_field] != base_class)\n    neg = large_dataframe.filter(large_dataframe[class_field] == base_class)\n    total_pos = pos.count()\n    total_neg = neg.count()\n    fraction=float(total_pos*ratio)/float(total_neg)\n    sampled = neg.sample(False,fraction)\n    \n    return sampled.union(pos)\nsampled = resample(vectorized, 6, 'StartHesitation', 0)\nsampled.select(\"StartHesitation\").groupBy(\"StartHesitation\").count().show()"}, {"cell_type": "code", "execution_count": 23, "id": "12368b8e-7a0f-40e4-8bc0-e66b378dad9f", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Overall\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Accuracy 0.717741935483871\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "F1 0.6161746804625685\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "label: 0.0, TP: 89.0, TN: 1.0, FP: 2.0, FN: 32.0\nlabel: 1.0, TP: 0.0, TN: 103.0, FP: 18.0, FN: 3.0\n0.0\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Accuracy 0.7258064516129032\nF1 0.8476190476190476\n1.0\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 212:====================================================>(915 + 1) / 916]\r"}, {"name": "stdout", "output_type": "stream", "text": "Accuracy 0.8306451612903226\nF1 0\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "(MulticlassClassificationEvaluator_b097261f9f2d,\n {0.0: 0.7258064516129032, 1.0: 0.8306451612903226},\n {0.0: 0.8476190476190476, 1.0: 0})"}, "execution_count": 23, "metadata": {}, "output_type": "execute_result"}], "source": "# binary target=1, undersampled majority\ntrain, test = sampled.randomSplit([0.8, 0.2],0.0)\npredictions = run_logreg(train, test, 'StartHesitation')\nevaluate(predictions, [0.0, 1.0])"}, {"cell_type": "code", "execution_count": 25, "id": "a52d7749-60ff-4519-a5c7-74e9e9418ce7", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 219:====================================================>(115 + 1) / 116]\r"}, {"name": "stdout", "output_type": "stream", "text": "+----------+-----+\n|prediction|count|\n+----------+-----+\n|       0.0|  114|\n|       1.0|    6|\n+----------+-----+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "predictions.groupBy(\"prediction\").count().show()"}, {"cell_type": "markdown", "id": "14930568-57fa-4b47-8540-1650e989481e", "metadata": {}, "source": "This is better since we're at least trying to predict the label, but we've had to severely undersample the data."}, {"cell_type": "markdown", "id": "cd9b333c-c971-4253-940c-9fbc7c5f9cb0", "metadata": {}, "source": "Now treat label 3=walking as binary"}, {"cell_type": "code", "execution_count": 26, "id": "784c358d-b61b-4ea8-bb0e-0f9daa5071aa", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 224:====================================================>(457 + 1) / 458]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-------+-------+\n|Walking|  count|\n+-------+-------+\n|      1|  70521|\n|      0|4040802|\n+-------+-------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "vectorized.groupBy('Walking').count().show()"}, {"cell_type": "code", "execution_count": 27, "id": "18cbdffd-2e88-4640-89bc-649be84e2070", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Overall\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Accuracy 0.8814391796967651\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "F1 0.8259069220697919\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "label: 0.0, TP: 724662.0, TN: 0.0, FP: 11.0, FN: 97462.0\nlabel: 1.0, TP: 0.0, TN: 822103.0, FP: 21.0, FN: 11.0\n0.0\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Accuracy 0.8814391796967651\nF1 0.9369839739797788\n1.0\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 287:====================================================>(457 + 1) / 458]\r"}, {"name": "stdout", "output_type": "stream", "text": "Accuracy 0.999961076952082\nF1 0\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# binary target=3\ntrain, test = vectorized.randomSplit([0.8, 0.2],0.0)\npredictions = run_logreg(train, test, 'Walking')\nevals = evaluate(predictions, [0.0, 1.0])"}, {"cell_type": "code", "execution_count": 28, "id": "7f4f42e2-9888-4c43-907a-0144dfd1e78f", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 289:====================================================>(457 + 1) / 458]\r"}, {"name": "stdout", "output_type": "stream", "text": "+----------+------+\n|prediction| count|\n+----------+------+\n|       0.0|822124|\n|       1.0|    11|\n+----------+------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "predictions.groupBy(\"prediction\").count().show()"}, {"cell_type": "markdown", "id": "145f7859-e2bc-4b67-9ea3-4c7e10529911", "metadata": {}, "source": "Now we try to undersampling"}, {"cell_type": "code", "execution_count": 16, "id": "c417e57e-4a17-4717-9b86-bcc86e60c7af", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+-------+------+\n|Walking| count|\n+-------+------+\n|      1| 70521|\n|      0|423703|\n+-------+------+\n\n"}], "source": "# undersample majority relative to \"Walking\"\nsampled = resample(vectorized, 6, 'Walking', 0)\nsampled.select(\"Walking\").groupBy(\"Walking\").count().show()"}, {"cell_type": "code", "execution_count": 18, "id": "df958948-29e7-4032-b115-542aa53cb725", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/05/22 17:59:34 WARN com.github.fommil.netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n23/05/22 17:59:34 WARN com.github.fommil.netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n                                                                                \r"}], "source": "# binary target=3, undersampled majority\ntrain, test = sampled.randomSplit([0.8, 0.2],0.0)\npredictions = run_logreg(train, test, 'Walking')"}, {"cell_type": "code", "execution_count": 19, "id": "1ce7bbe2-a7f0-447b-b7da-8f62b34e3a14", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Overall\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Accuracy 0.7694047787360384\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "F1 0.6686921174972204\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "label: 0.0, TP: 76051.0, TN: 2.0, FP: 34.0, FN: 23036.0\nlabel: 1.0, TP: 0.0, TN: 99084.0, FP: 3.0, FN: 36.0\n0.0\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Accuracy 0.767258860203989\nF1 0.8683008700020551\n1.0\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 117:====================================================>(963 + 1) / 964]\r"}, {"name": "stdout", "output_type": "stream", "text": "Accuracy 0.9996065494385763\nF1 0\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "evals = evaluate(predictions, [0.0, 1.0])"}, {"cell_type": "code", "execution_count": 21, "id": "a5c737df-02d1-404a-b494-8684b1672a75", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 122:====================================================>(963 + 1) / 964]\r"}, {"name": "stdout", "output_type": "stream", "text": "+----------+-----+\n|prediction|count|\n+----------+-----+\n|       0.0|99087|\n|       1.0|   36|\n+----------+-----+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "predictions.groupBy(\"prediction\").count().show()"}, {"cell_type": "markdown", "id": "0186dd88-f15c-4ca6-bf1c-a54dc991a467", "metadata": {}, "source": "Even though some models produce higher accuracies and F1 scores, they may not be the most sensitive models because they end up not being able to predict all of our labels. This is likely due to our unbalanced dataset, that has a lot of rows with labels=0, 2 and a relatively small number with labels=1, 3. Some areas to explore in the future could be a combination of undersampling and oversampling, or appying a method such as SMOTE to generate new data points."}, {"cell_type": "code", "execution_count": null, "id": "eb0a9c6a-7f9e-4ce1-a003-33d8352b0982", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.15"}}, "nbformat": 4, "nbformat_minor": 5}